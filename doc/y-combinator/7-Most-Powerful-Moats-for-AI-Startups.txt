Harj Taggar: This idea of moats is so pervasive and so important. It is interesting how moats have just become much more discussed by aspiring startup founders now than they were pre-AI.
Garry Tan: What is going to prevent you from being basically subject to infinite competition?
Harj Taggar: Like a moat is inherently a defensive thing and you have to have something to defend. If you have nothing to defend, don't worry about your moat.
Garry Tan: Welcome back to another episode of The Light Cone. Today, we're going to talk about motes. So in your head, you might be thinking about barbarians storming your gate. You've got this little startup, and you've got every other company out there who wants to come and eat your lunch. And right outside your castle is a mote that keeps them away. Jared, when you were going to college campuses, this isn't sort of this trivial thing that people are thinking about. It's actually something that keeps them from starting companies right now.
Jarred Friedman: Yeah, this is a question that we got from a lot of very smart college students on our recent college trips. And basically their question is like, they don't see how these new AI agent companies, like a lot of the ones that we've talked about on this podcast, Could have moats, um, it plays into this meme of like the chat GPT rapper that like all of these companies could be easily cloned. And so they can see how you could build a business that makes some amount of revenue, but they don't really see it. He can build a long enduring business.
Jarred Friedman: And so I think it's actually not true. I actually think these businesses do have quite deep and interesting modes, but they're not. totally obvious what they would be. So I think this is an interesting topic for us to explore.
Garry Tan: At our recent AI startup school backstage, I had this exchange with Sam Altman that I thought was kind of funny. We spend a lot of time thinking about make something people want. very simple maxims that are sort of anti-business school. And yet this idea of moats is so pervasive and so important. We sort of remarked how funny it is that one of the more important books to read these days is actually business school fodder, this book called The Seven Powers. So today we thought that we would actually go through those seven powers. What are they?
Garry Tan: What are some concrete examples? and ways that a startup founder who's just starting out could or should be thinking about these things from real world examples that we've seen.
Jarred Friedman: So, Diana, can you tell us a bit about this book?
Diana Hu: This book was written by Hamilton Helmer, who taught at Stanford Economic School and was published in 2016. And the book title was The Seven Powers, The Foundations of Business Strategies. And a lot of the examples are more with the era of internet companies from the 2000s. So a lot of the examples are like, Oracle, Facebook, Netflix, which is an older generation. So we want to do a bit of a reboot right now, How It Applies Now 2025 with AI.
Jarred Friedman: I think it's a little bit confusing the way he uses the terminology in the book. It's called the seven powers, but it would make a lot more sense if he just called the thing the seven motes, because that's really what he's talking about. He's really talking about seven categories of motes that a business can have. And it's true that the examples are out of date, but I think the framework is actually pretty timeless. It turns out there's just only so many kinds of motes that a business can have, and they don't really change. And so even though the specific versions of these motes are different in the agent world, the categories haven't changed.
Garry Tan: Thankfully we live in a world where there's markets and there's free markets where there's lots and lots of competition. And these moats, in a lot of ways, are the only way, if you're running a business, you can sort of fight against all of the other people who might want to do exactly what you're doing. And famously Peter Thiel talks about competition is for losers. And so the profound view there is that given infinite competition, what is going to prevent you from being basically subject to infinite competition? And then as a result, your margins, how much you can actually profit off of what you're selling goes down to zero.
Garry Tan: And what that means is actually your business will die. And so having a moat is relatively existential, eventually.
Jarred Friedman: You made a great point earlier, Gary, that this is actually like, you kind of have to worry about this at the right time of a startup. Do you want to talk about how early stage founders should think about moats?
Garry Tan: I mean, this is sort of why we generally tell people to go find a person with a real problem and then go solve that problem first. What's funny about the world that's a little surprising is that you can go almost anywhere and find some pain point, some problem that could be solved with software and especially with AI that frankly just isn't being solved. They're so numerous and so severe that if you find that thing and solve it, you literally can mint a billion dollar or 10 billion or even hundreds or hundreds of billions of dollars market cap business.
Garry Tan: And it's just lying in plain sight. That's really the first thing that people should do. You should just find a problem and go solve it. And then along the way, you will probably, as you work with customers, as you build the product itself and engineer it and figure out what data you need for it and all of these things, you will stumble upon these seven powers.
Jarred Friedman: Yeah, the moots come later. Like you would be like pretty dumb for somebody to decide not to work on a startup idea because they can't see what the long-term moats of that idea could be, right?
Harj Taggar: It is interesting how moats have just become much more discussed by aspiring startup founders now than they were pre-AI. Seems like the main reason for that presumably is just that the original chat GBT rapper meme and that the moat that most people are worried about is moat against the big model companies and how, like, are you not gonna get crushed by one of the big labs when they decide the product you're working on is really valuable and they want to own it too.
Diana Hu: And I think Varun from Windsurf, who we hosted some time ago, he said it himself, the early stages at the beginning, the only mile that startups have is really just speed. Once you pass that and build something that people want, then you figure out and go deeper into these types of modes that we're going to discuss.
Jarred Friedman: I really like Varun's point that the only mode is speed. That is not one of the seven powers in the book, but I think it probably should be.
Diana Hu: I think it also comes with a lot of the essays from PD, because one of the tenets really at the beginning is, yes, you're a big company, let's say OpenAI. OpenAI is the new Google. Sure, OpenAI or Anthropic could build all these features, let's say like cloud code, and then compete directly, let's say, Cursor, et cetera. And for a startup like Cursor to really win even in the beginning is they had relentless execution because a larger company like a Google or Anthropic, they just have a lot of more craft that they need to do in order to ship a product.
Diana Hu: They just have all these product managers, all the operations, they need to go through a PRD, some spec doc, and it takes a lot more time to ship a feature. As opposed to cursor. The incredible story about cursor when we hosted Michael Truell to come talk to the badge. He was sharing how his product development cycle for shipping features and sprint cycles were one day.
Jarred Friedman: One day. So one day sprint.
Diana Hu: In the, at the beginning during a 2023, 2024 around era, they would start the, every day would restart the clock and try to ship things every day. I mean, that's like insane speed. Like there's no big company that could ship something at that speed. At most weeks, couple of weeks, and maybe the larger companies, I don't know if you're Google, maybe like multiple months or sometimes years. I mean, they had Google Bart or Gemini a long time ago. That took years to get out, right?
Harj Taggar: I think Kirsten and Windsor are great examples of when you should start thinking about the moats because for the first few years, I didn't think it really mattered that much. They just had to, like, they proved out that hey, like, cogen is going to be a really valuable application of AI, the development environment is going to be very, very important to own, they, like, got rapid growth, and then to only when they're at scale that, you know, like, they have to start thinking about how are we going to defend against, like, code or codex or all the other things coming in.
Harj Taggar: And the mental model that's really stuck with me is when we spoke to Bob McGrew a couple of weeks ago. And I think Jared, you brought this up, actually. One way you could think about it is that all of these startups are kind of forward deployed engineering teams for the labs, maybe. And so early on, actually, because this is all green field, we don't actually know what the valuable verticals and products to build are. So in a sense, step one is just figure out what that is. And it wasn't actually, even two years ago, it wasn't actually clear.
Harj Taggar: CodeGen or the IDE. Once you figure that out and you find any sort of struck gold and you keep digging, that's when you have to probably at some point, you're going to get more competition because people are going to realize, oh, this is really valuable. There's lots of money to be made here. And then you have to start like defending like the treasure you found.
Garry Tan: So I mean, all the things that we're about to cover, aside from speed, are sort of one to a billion, one to 10 billion, one to a hundred billion, one to a trillion dollar sort of problems. And then the real stupid thing that people might do is watch this and look for this as a reason to not even get to one.
Jarred Friedman: So that would be probably the- Or try to use it to like pick between two different startup ideas because they're like trying to forecast five years in the future, which one will have a greater moot.
Garry Tan: Which just isn't how it works.
Harj Taggar: I mean, literally, you shouldn't do that. Like a moat is inherently a defensive thing and you have to have something to defend. Otherwise, like... If you have nothing to defend, don't worry about your moat. Otherwise, it's just like a puddle in the field. Exactly. Let's assume that someone has found something that's valuable that is worth defending. Should we talk through what some of the moats they could think about are?
Jarred Friedman: Yeah, so process power again like the terminology is kind of funky but like basically it means you built something that's like you built a very complicated business with a lot of stuff. That's just hard for people to replicate just because you'd like build all the stuff. And so the example that he uses in his book is like the Toyota assembly line. And I think the AI agent version of this is just a really complicated AI agent that's been like finely honed over like multiple years to work really well under real world conditions. We've talked about a bunch of these on this podcast, like Jake Heller with case text is like the original example.
Jarred Friedman: A couple other ones I was thinking about from more recent companies, we have like A couple companies that sell AI agents to banks. We have Greenlight, who worked with Tom. They do KYC for banks. And we have Casca, which does loan origination for banks. So it essentially tells banks which loans they should give. And I think these are interesting examples because for all of these AI agents, you could build a version of Greenlight or Casca or Casetex, like a demo version in a weekend hackathon. And I think when college students are thinking about these AI agents, I think what they have in their mind is the weekend hackathon version of the product.
Jarred Friedman: And they're like, I could build that in a week. How could that be defensible? And the reason is the version you build in a hackathon isn't useful to anyone. If Casca or Greenlight fail, the banks will lose millions of dollars. This is mission-critical infrastructure. It's more like a self-driving car.
Garry Tan: One way to look at it is way better engineering. Is actually that's like the most profound form of process power like one example might be plaid which you know the surface area of the number of Financial institutions that they have to support is so giant. It's you know, probably thought on the order of thousands to tens of thousands of different different websites, different crawlers, and then all of the different, you know, can you imagine like Plaid CICD structure? And then, you know, this is pure speculation, but if I were Zach running Plaid, like I, you know, know that I would want to be using CodeGen tool, the latest CodeGen tools to be able to basically add every new financial institution on the planet quicker than anyone else.
Garry Tan: That's sort of a very profound form of process power in the modern AI age.
Jarred Friedman: I think this is probably the main form of defensibility for the existing SaaS companies. If you look one generation before the AI agent companies, Why is Stripe or Rippling or Gusto defensible? I think it's mostly this, right? It's just like, they've just built a lot of software and it'd be really expensive and hard to replicate all of it. And like you can't just copy it from their landing page. Like there's like, like the backend logic is like super deep.
Harj Taggar: There's also I feel like kind of a schlep blindness aspect to this going on to where like the hackathon version of any AI tool is like quicker than ever to get to but actually the last like 10% of getting it to work reliably across like tens of thousands of KYC requests like per day is sort of like a particular type of painstaking drudgery work in a way that I think like lots of engineers just not excited to do. And then that is also kind of like the teams that open AI are going to experience this too right like if you're, if you're working in one of the big model labs and there's teams of people trying to invent AGI It's going to be hard to get jazzed about nailing the final 5% consistency on your KYC tool.
Jarred Friedman: I think this is especially true for verticals like KYC that require specialized knowledge to even know what the edge cases are. We had to pick from the seven powers. I think speed and this, these are probably the two dominant ones that come up the most often.
Garry Tan: And those are most related to execution.
Diana Hu: It's where the hardcore builders win. Having really good product taste and building the best product really matters. And I think it comes to a lot of the point, maybe the misconception is I think a lot of these products, you can probably build the 80% solution with 20% of the effort. But for these solutions and products to work, you need the 99% accuracy one, which then takes like ten times or even sometimes hundred times them on an effort, right? It's sort of that Pareto principle type of thing. What about the other power for corner resources?
Garry Tan: I think the classic view is they're just coveted assets or things that they're not arbitrageable. They must be independently valuable. And then sometimes they offer preferential access with rates that are way lower. So the classic example that you could look at is pharma companies have these patents that are very hard to get. They have to come up with them and then prove them and get through regulatory approval. And the sheer fact that they have a patent plus getting through FDA approval is something that can be very durable. And it's so powerful that Patents have a limited lifespan because you don't want people to have that forever.
Garry Tan: A more modern example, I think, on the regulatory side might be scale AI is doing a ton of work with the DoD, be a Palantir as well. In order to even get there, it's a painstaking process. You've got to hire the right people. You've got to spend a lot of time in DC and Langley or wherever you're trying to sell to. And you've got to literally build skiffs, like these sort of special data centers where it's at great pain and expense. You have to get embedded with the government. But then when you do, well, you've got it.
Garry Tan: The corner resource in some sense is even the brain space in people who work in the government. Right now, if you're working with AI, you've got to go through a palantir or a scale, and that's literally written into their public documents around how they're thinking about the nature of warfare and the nature of everything that they want to do having to do with AI moving forward. So the corner resource doesn't have to be a diamond mine, it could be the diamond mine in your customers' heads. Those examples are closer to being way up in the sky, having this insane dekakorn worth hundreds of billions of dollars situation.
Garry Tan: But what's relevant for startups that I think all of us see every day is what you were mentioning with this FDE forward deployed engineer model that That is what a lot of startups that are extremely successful today are literally doing like they're going out and getting a cornered resource in the form of real data and real workflows. Literally sitting with a customer who normally would never get access to good software. And then spotting, okay, this is sort of the tailored time and motion, you know, first a request comes in by email. Then we take this and we enrich it in this way.
Garry Tan: Sometimes we have to have a call center, call this person, like, you know, actually understanding what might be a very boring process. And then translating that into your own prompts, your own evals, eventually your own data sets to tune your own models. Like those are all things that are incredibly valuable. And then clearly there are examples, earlier we were saying like character AI, for instance, took LLMs, obviously built some of the first LLMs, took many of them and then fine-tuned them in a way so that they could bring down the cost of serving those models by 10x.
Garry Tan: And so that itself is also a form of a cornered resource.
Harj Taggar: The best cornered resource to have is your own model that can do the specific work better, right?
Jarred Friedman: And for a while people thought that was the only mode that you could have in this space. If you didn't have your own model, you were totally hosed. Turns out that's not true. Turns out there's just one of the possible modes.
Harj Taggar: Partly that is a threat people are worried about in the big picture. The 10,000 foot scary thing is if the labs at some point decide treat their models as a cornered resource and they restrict access.
Garry Tan: I guess the interesting thing right now is like it may well be true that the platonic ideal perfect manifestation of an AI system will require a lot of both maybe pre-training, post-training, RLHF, just so many different things that you have to throw at it to get it to chat GPT level. But we're also so early in the revolution that You know, even if just context engineering gets you 80 or 90 percent of the way there, that's plenty. That's actually all people need to do for like the first two years of their startup, almost always. You know, Cursor didn't start out by doing, you know, full parameter fine-tunes of GPT-5, which they probably have access to now.
Garry Tan: They started just by making something people want. Earlier we were saying like, don't use these frameworks to count yourself out prematurely. And this is a very profound version of that.
Diana Hu: So the third power we're going to discuss is switching costs. That is the concept where you get up mode when your customers are kind of trapped because it becomes very expensive for them to find other solution. Even if the other solution might be like a little bit better, it's just very painful for them to switch financially or in terms of the operations, times or effort, because they just have so much of it in the current solution. And examples that are given in the book are databases like Oracle. When you have all of your system or record and all your data in Oracle, it becomes incredibly hard to migrate.
Diana Hu: Database migration is something that people don't do. Other example given is Salesforce. And because once you have all your customer records in Salesforce, you build all these workflows, the UI, and it's just a lot to retrain a lot of your sales team to use a new software. You need to migrate all the data. And then at that point, for the company to switch to a new CRM is probably going to take, I don't know, lose a whole year of productivity or something, even if the new solution is a little bit better. I think how AI companies are building mode with this has to do with a version of what Gary mentioned with the forward deploy engineer.
Diana Hu: We've given examples of this with Happy Robot or Salient, where they start with specific workflows that are very customized per company. And they work with large enterprises. And part of it is actually with the forward deployment engineer, they may have actually very long pilot periods, which might last like six months to a year. But if they succeed, these convert into seven-figure contracts. And the reason why these pilots are so long is because they're very much building custom software for the specific operations in these companies. And the examples for Happy Robot, they got customers like DHL, where they went deep into integrating into a lot of the workflows for how all their logistic operations are done, which is very custom to the DHL operation.
Diana Hu: Or the example for Salient, who's building AI voice agent for the financial industry. They integrate with banks and a lot of the banks have very different workflows on how they do a lot of the loan consolidation, how do you do the debt recovery, how they do a lot of the fraud monitoring and risk and compliance. And it's all a little bit different because all these companies have built kind of internal tools and the whole part of bringing AI company that builds these workflows, they build custom workflows then that work with them. But as a result, the trade-off is you do have very long pilot cycles, but the protocol is worth it because you end up with this big contract.
Diana Hu: And once you're in, you're kind of minted. And the big enterprise is not going to do another bake-off because it's going to be a huge waste of time for them to, let's try the other whatever cool AI voice agent company at that point is that we just want to get the benefits. So that's how these AI companies are winning.
Garry Tan: I think it's like at once a moat and it's also interesting in the age of AI that simultaneously you could see how AI brings down the cost of switching by a lot. And that's sort of another lever that a startup could use. Like if you can write, use cogen, to basically extract data out of old ossified systems or your competitors, then there are things that might have really relied on switching costs that you could potentially bring it down to zero.
Jarred Friedman: Yeah, there's actually two different flavors of switching costs, right? There's the old-school ones from the SaaS era, All the system of records like Salesforce, but also ETS is like like Lever and Ashby were where the switching costs was the painfulness of migrating data from one system to another. And I agree with Gary. LLMs might significantly reduce the switching costs because the LLMs can figure out how to like morph the data from the old schema into the new schema. You can use browser automation on both sides to solve issues where people don't let you export the data.
Jarred Friedman: But then there's this new form of switching costs that I think is pretty native to the AI era, like you're talking about, to Tiana, which is these lengthy onboarding processes that lead to deep customizations of the logic of the agent, not just the data. that didn't really exist in the SaaS era. I guess you'd customize your Zendesk implementation a little bit, but not that much.
Garry Tan: And then for AI companies on the consumer side, this is all very nascent, but I think memory is already becoming a bit of a switching cost for me. It actually blew me away that Claude was so behind on memory. And then, you know, my relationship with ChetGPT, I feel like has evolved very significantly in the last year where I'm like, oh, I actually just generally, it seems to know, you know, what I'm into and what I care about. So, you know, that switching cost, I think over time will only become greater and greater. And so personalization for consumer is actually a huge piece of that.
Diana Hu: What about counter positioning the other moat on the book?
Jarred Friedman: The definition of counter positioning is doing something that is difficult for the incumbent that you are competing with to copy because it would cannibalize their business. I think there's a couple of ways that this plays out. In every category, there is a Darwinian competition. between the existing SaaS incumbents building their own AI agents and the new AI native companies building AI agents on top of the existing SaaS companies. So like for customer support, the existing SaaS incumbents like Zendesk and Intercom and Front are all building their own AI agents. But then we have like a new wave of companies that grew up in the last couple of years that are building AI agents that interface with the system.
Jarred Friedman: I think it's like I don't know, this could be a topic of a whole, like, light cone episode, which, like, who will win in each of these fights? I think it was really interesting.
Garry Tan: unstoppable force meets the movable object.
Jarred Friedman: One way where this is playing out in the counter positioning is that almost all these house incumbents, their pricing model, is they charge per seat, i.e. per employee. And this is, I think, a very big Achilles heel that they have strategically, which is that if their AI agents do a good job and actually work, those companies will need fewer employees doing this work because they're Like the work will be automated by AI agents and in a and in a simplistic way that will just actually reduce the more successful they are the more they will reduce the revenue My guess is like some of them will be able to navigate this like especially if they're still founder controlled I think like intercom for example like the I think the founder controlled versions of these companies are smart enough to recognize that this is Existential and they may be able to cannibalize themselves.
Jarred Friedman: I think the ones are not founder controlled I don't have a lot of hope for it's super hard to cannibalize your own
Harj Taggar: revenue. The alternative as we're seeing is so much of the startups pricing models are around sort of like work delivered or tasks completed. I think it's exactly what you said but it's also that then switches the product towards having to actually be able to complete the work and something I actually repeat at the last YC batch at the end as closing advice is that I wish the founders in a batch could just somehow go spend a month at some of the late stage companies because the top thing we hear from the founders running those companies is how hard a time they're having sort of resetting the engineering culture in their org to actually embrace AI to use the tools to want to do like context engineering and prompt engineering and the net result of these teams not actually being able to be AI native, one of the better term, is that they just can't deliver the
Harj Taggar: products that work, right? And so they both don't want to switch from per seat pricing because that's what they're used to. And in a world of AI being able to do the work, there's going to be less seats to sell to. But they also just cannot deliver on products that can do the work. And so that pricing model is not going to make any sense to them either.
Jarred Friedman: Yeah, it's like the process engineering part. They're not good at the process engineering part for this new kind of engineering.
Garry Tan: I mean, something sort of emerging that's very interesting in a bunch of YC startups like Avoka, for instance, they're doing customer support software kind of like Service Titan, but for HVAC. So literally like people who help you with heating and air conditioning. And I think Service Titan has something like 1% wallet share, 1% of the gross transaction value of a given HVAC company, which is very small, right? I mean, people don't spend that much money on software because these are relatively low-margin service businesses. But the wild thing that Avoka discovered is that, you know, they can come in as software, but then over time, they're actually getting a bigger and bigger chunk of the wallet share because they can get the HVAC people to pay them actually for the customer support piece, which is not 1% of their spend, but 4 to 10% of their spend.
Garry Tan: So what you may well find is that this new breed of AI startup will actually have more growth and higher wallet share. So, you know, actually we may well be all undervaluing how powerful and how big the vertical SaaS AI companies will actually be because you're not like 1% of wallet share. You can get to 10.
Diana Hu: That's what we talked in that episode where vertical AI SaaS agents will be 10 times, at least 10 times bigger than SaaS because it's really to your point, Gary, tapping into a whole different part of the spend of the companies is not the wallet of software where you're kind of at this point, I suppose is a bit of a finite budget, but is really new space with things that were not done possible. And it was mostly workflows from, from people.
Garry Tan: And I know that people are pretty sensitive about workforce displacement, but customer support for an HVAC services company is not a fun job. And you can tell because all of these customer support jobs actually have like 50, 80% annual attrition rates. They're just such torturous, not fun jobs that the companies themselves and the call centers themselves spend almost all of their time trying to vet and bring in more people to work on these terrible jobs. And so when you have better software, what's sort of happening is that instead of people aren't losing their jobs, these people are quitting their jobs anyway because it's a terrible job.
Garry Tan: And then if anything, what Avoka has told me is that many of the people who were in those customer support sort of roles, now they're actually having more fun jobs because instead of like managing a whole set of people who don't want to be there, they're actually managing AI agents and then handling the interesting weird cases. The coolest part of it is like they actually can go in and sometimes alter the prompts. And sometimes you actually have a direct impact on both the experience of the customer, but then also their own day to day. And that immediately is like a 10 times more interesting job, like wrangling a bunch of AI agents and making the support process better and better over time.
Garry Tan: Like that's, you know, as knowledge work goes, like way more interesting than follow this script and read what the computer says.
Jarred Friedman: So Harj, you had a really interesting point about a second form of counter positioning.
Harj Taggar: This space has moved so quickly that in every vertical, or many verticals, there's sort of early on emerged one company that's seen as the early winner in the space. Often it's actually like the second movers, at least within the YC context, we have seen over and over again that like there's advantage to being the second mover in a space. Like Stripe came after Braintree and Authorize.net and a bunch of things and was able to like actually win by just building a better product. DoorDash came after Grubhub, Postmates, various other delivery services and eventually went on to win.
Harj Taggar: And so I think it's interesting to sort of just consider about if you're entering a vertical where it's already feels competitive or there are already there's already seemed to be like a early winner in the space how do you counter position against them one thing i think is really interesting here is legora versus harvey legora is obviously uh both in the legal ai space harvey is the early winner the counter positioning that i see from legora is harvey came in early and maybe got early sales um but focused a lot on fine tuning as sort of like their product differentiation when over time it's seen that that was probably not the right move.
Harj Taggar: You wanted to actually focus in on the application layer and actually just sort of building a better product. And Legora has focused on that. That's what their branding positioning is. And it seems to be working really well for them as a second mover into the space. A company that I've worked more closely with GigaML entered the customer service space and they're competing with Sierra and DecaCon, like really well-known customer support companies. And from having seen their sales motion, how they've been able to sign up some big customers, I think their counter positioning is their product fundamentally just works better out of the box.
Harj Taggar: And as a result, they can have a much faster sales and onboarding process. So it's like their counter positioning is if you want to sort of get your customer support working as quickly as possible, you should go through like the GigaML onboarding process versus like the Decanong. And I think that's actually worked quite well for them.
Jarred Friedman: Yeah, GigaML is an interesting example of how, to your point about, like, hybrid displacement, it's clear that an AI agent can do this job not just as well as a human, but actually much better than a human. Like, the door dashers that the GigaML agents are talking to, a lot of them don't speak very good English. They speak all kinds of languages. You can't hire a customer support person who's fluent in 200 languages. But the LMs are, actually, out of the box. And they're infinitely patient if like there's a bad connection or so that's pretty interesting.
Diana Hu: I think you have other example where to your point of a superhuman abilities is where the AI version of the product actually works. I think you had the example of a Duolingo versus Speak.
Harj Taggar: Duolingo is obviously the biggest language learning app, I think most consumers know. The emerging criticism of it, I would say, is that it's actually just sort of like a gaming app versus a language learning app. The way the app works is orthogonal to learning a true language. And then you have Speak, which uses LLM, like uses voice to actually help you practice and actually learn the language. And that counter positioning is working really well for them, right? Speakers got explosive growth and it's not trying to compete with Duolingo on there. We've got like lots of gamification and points and sort of like a great game mechanic.
Harj Taggar: It's competing on, hey, we're actually just the place you should come if you want to learn the language by speaking it. I think the counter positioning mode is very close and overlaps with the branding mode idea. I think in the book he talks about brand is, it's essentially a mode when you become so well known that even if you have an equivalent product, consumers will still choose you because of the brand effects. And I think the example is like Coca-Cola. In the AI context, I think it's probably harder to apply brand as a mode directly to startups.
Harj Taggar: It just takes time to acquire brand. But you can certainly see its effects. Like the thing that still stuns me is OpenAI ChatGBT has more consumers using it per day than Google's Gemini. I think anyone who understands the models and uses them daily would say that Gemini Pro 2.5 and Gemini Flash 2.5 are like equivalent models.
Jarred Friedman: And Google also had all the users. Like basically everyone in the world is a user of Google.
Harj Taggar: Open AI had no users initially. Google was already one of the biggest consumer brands on the planet. It was almost certainly the biggest consumer brand on the internet and yet somebody else came along and built the brand as the consumer AI app and Google is like playing catch-up.
Jarred Friedman: If someone had told me in 2022 that that's how it would play out, I would have been fairly incredulous.
Garry Tan: It's also a perfect example of counter positioning again. I mean, this is Google had a business model that required it to continue to support ads and an organization that they shipped and so You have the greatest cash cow in the history of man, so why would you disrupt it, even at the cost of sending back human access to knowledge by a few years, even if that's the core stated goal of Google itself, to organize the world's information?
Diana Hu: There's also the untold story of how the origin story of ChachiPT, how it came to be, which is really the original mode for startups with speed. It shipped very quickly in a matter of months with a very small team of a couple of engineers.
Garry Tan: I mean, it required Sam Altman and YC Research and Greg Brockman to go hire Ilya Sudskiver out of DeepMind, because he was there. And a lot of the people who went on to help create OpenAI, they came from DeepMind. It was already in the right place. It's just that that place didn't nurture exactly the thing that society really needed.
Diana Hu: For speed.
Garry Tan: So there's that mode again, speed, number one. Do you want to talk about network economies, Diana?
Diana Hu: Yeah, on the book Network Economy is described as where the value of the product increases as more users or customer get and use the product and everyone derives more value as a effect of more people using it. And examples that were given in the book are Facebook, where as you use it and your friends use it, it's more fun for me to use Facebook because all my friends are in there. As more users come in, then the social network becomes more valuable. And this was very much the era of the internet where people talked about network effects that came to be.
Diana Hu: And the other example he gives is like Visa, the Visa network, where the more merchants are using Visa, the more value the consumer gets because you can swipe the Visa card in more places. Then that becomes the moat because it's harder to then acquire and amass this number and large number of users or merchants in order to win. So that becomes very defensible. In the current era for AI, the shape of network effects is different. It really comes into the shape of data. I think a lot of The data that a lot of AI companies get access to becomes the mode where the more data they get, the custom models they build become better, and the better models, it becomes a better product for users.
Diana Hu: And there's lots of examples of these. And besides the big foundation lab companies where they probably use some of the data from the users, probably do.
Garry Tan: ChatGPT almost certainly feeds a lot of that back because you have a certain reward function for each training run, right?
Diana Hu: So all the history of every chat from chatGPT 1, 2, 3, 4, 5 now goes fed into GPT 6 and then so on and so forth helps create the the next model version. And there's even smaller versions of this, for example, Cursor. They have probably one of the best tap-tap autocomplete because the free version of Cursor, they actually say it when you sign up that they will use the data and they use that to train it. And the more users they get...
Jarred Friedman: all the data like I think it's like quite utterly like every mouse click and every keystroke that you that you admit when you're using cursor like is fed into a model which is like kind of crazy.
Diana Hu: Which then the more developers use Cursor, the better the product gets. And then they compound a lot of the, a lot of the wins with that. And the version where this applies to AI startup is when they go work with enterprises and large companies, they get access to private data. I mentioned earlier, Celian or Happy Robot, when the employees of the companies where they become customers, as they use their product, they have a lot of that private data that makes a lot of the workflows better. And the way they improve that, which is the second way of having modes with networks is really evals.
Diana Hu: We talked a lot about evals being the key mode for AI startups is evals is where you get a lot of this workflow work or didn't work and then take that back and iterate and improve your context engineering. And that is a flywheel that you can only achieve when you get more and more usage of your product, whether it be in a consumer or a or an AI vertical SAS agent. So now the last mode in the book is scale economies. Jared, do you want to tell us about it?
Jarred Friedman: scale economies or economies of scale. You've invested a lot of money to build something that's really big. And as a result, you have economies of scale and you can offer the service cheaper than anybody else. So like the classic example would be like UPS or FedEx or the Amazon delivery headwork. They built like massive, like physical infrastructure. And as a result, they have like a lower cost per unit compared to a smaller competitor. I think the way this has played out in the AI world, I don't think it's actually played out that much at the application layer.
Jarred Friedman: It's really played out at the model layer, right? Like training a state-of-the-art LLM is very capital intensive. Only a few companies can afford to do it. Once you've done it, you can afford to like let people do inference on that model very inexpensively. This is why the deep-seeking announcement was so was so earth-shattering last year, because it seemed like it might be a lot cheaper than people previously thought to train a frontier LLM, which would greatly diminish the power of this economies of scale that people thought the AI labs had.
Diana Hu: The key thing about DeepSeq was they figure out and made public this new unlock for models, which is how to do RL. They still build on top of one of the large foundation models, so it's still expensive. That rail part is cheaper, but you still need the very expensive big foundation model. So that's one of the things that media got wrong.
Jarred Friedman: There's a separate question that people talk about, which is like, how will the foundation Model companies be defensible against each other. And like, this is certainly one way, right? It's just like, it's, it's very hard to be a new entry into that game now because of this account. And we were, we were thinking earlier about like how this had played out with startups. And there's not that many examples, but I think a couple of good ones. Well, one, one good one is as a company of yours, EXA. Harj, do you want to explain what, what EXA does?
Harj Taggar: Yeah. Exa is essentially search for AI agents. Um, it provides an API for anyone building AI applications that wants to search the web.
Jarred Friedman: And the way I think this is playing out for Exa is in order to provide that service, they need to crawl the web, not the whole web like Google does, but a big chunk of it. And that's very expensive to do. It requires like a large, like fixed capital investment. But then once, once you crawl a big chunk of the web, you can reuse that same crawl for, for many different customers.
Harj Taggar: I think what's interesting about Exo, the parallel to the model companies is that they had invested in that before agents had really taken off. They were fairly early to this. I think they were working on this actually even pre-Chat GBT launching. So they made the investment early on, took a bet, same way that the lab companies took a bet on transformers and scaling laws.
Jarred Friedman: And there are two companies in just the most recent batch, Channel 3 and Orange Lice, that are both doing Exa.ai-like plays where they crawl a big chunk of the web, have a big static crawl on their own servers, and then have agents that run on top of that crawl. So I think we're going to see more and more of this, especially as the web agents work better.
Garry Tan: You need to mainly focus on the first moat that isn't even in the book, which is speed. If you're really breaking your brain about like, oh, well, are we going to be a cornered resource or not? You're just thinking about it in the wrong way. You should not start there. You should start with, do I have a specific person who has some sort of pain point? And it's pretty painful. It's not like, oh, it'd be nice if I could do this. It's a, oh, I am not going to get promoted this year. Maybe I will get fired.
Garry Tan: Like, this is so painful that I don't want to go to work today. Like, that's sort of the type of pain that you're looking for. And if you can write software or build things that actually alleviate that pain, like existential pain, like the business is going to go out of business, or, oh my god, we could totally take over everything next year. Like, that's sort of the feeling that you want in your customer. If you can find things like that, go find that and go zero to one on that first. With that, see you guys next time.